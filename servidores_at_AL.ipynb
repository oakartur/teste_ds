{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os as os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get csv files from url\n",
    "url = \"https://www.tesourotransparente.gov.br/ckan/dataset/transferencias-obrigatorias-da-uniao\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = soup.find_all('a', {'class': 'resource-url-analytics'})\n",
    "\n",
    "    if links:\n",
    "        for link in links:\n",
    "            csv_url = link.get('href')\n",
    "            csv_response = requests.get(csv_url)\n",
    "            \n",
    "            if csv_response.status_code == 200:\n",
    "                file_name = csv_url.split(\"/\")[-1]\n",
    "                with open(file_name, \"wb\") as csv_file:\n",
    "                    csv_file.write(csv_response.content)\n",
    "                print(f\"Download of {file_name} completed successfully.\")\n",
    "            else:\n",
    "                print(f\"Failed to download the CSV file: {csv_url}\")\n",
    "    else:\n",
    "        print(\"Links to the CSV files not found on the page.\")\n",
    "else:\n",
    "    print(\"Failed to access the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check csv file encoding\n",
    "def detect_encoding(arquivo):\n",
    "    with open(arquivo, 'rb') as f:\n",
    "        encode = chardet.detect(f.read())\n",
    "        print('Encoding:', encode)\n",
    "    return encode\n",
    "\n",
    "ITR_encoding = detect_encoding('C:/Codes/teste_ds/ITR.csv')\n",
    "FPM_encoding = detect_encoding('C:/Codes/teste_ds/FPM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv files into pandas DataFrames\n",
    "address = 'C:/Codes/teste_ds/'\n",
    "\n",
    "csv_files = [f for f in os.listdir(address) if f.endswith('.csv')]\n",
    "dataframes = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    full_path = os.path.join(address, file)\n",
    "    df_name = os.path.splitext(file)[0]\n",
    "    dataframes[df_name] = pd.read_csv(full_path, encoding='ISO-8859-1', delimiter=';', skiprows=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dfs\n",
    "count_dfs = 0\n",
    "for df_name, df in dataframes.items():\n",
    "    print(f'DataFrame Name: {df_name}')\n",
    "    count_dfs = count_dfs+1\n",
    "print(count_dfs)\n",
    "\n",
    "print(dataframes['CIDEEST'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace categorical month/year to numeric and handle missing data, keep AL only \n",
    "for df_name, df in dataframes.items():\n",
    "    dataframes[df_name].replace('-', pd.NA)\n",
    "    dataframes[df_name].fillna(0)\n",
    "    \n",
    "    dataframes[df_name] = dataframes[df_name][(dataframes[df_name]['UF'] == 'AL')]\n",
    "    \"\"\"dataframes[df_name]=dataframes[df_name].rename(columns=lambda x: x.replace(\"janeiro\", \"1\").replace(\"fevereiro\", \"2\").replace(\"março\", \"3\").\n",
    "                               replace(\"abril\", \"4\").replace(\"maio\", \"5\").replace(\"junho\", \"6\").replace(\"julho\", \"7\").replace(\"agosto\", \"8\").\n",
    "                               replace(\"setembro\", \"9\").replace(\"outubro\", \"10\").replace(\"novembro\", \"11\").replace(\"dezembro\", \"12\"))\"\"\"\n",
    "    dataframes[df_name]=dataframes[df_name].rename(columns=lambda x: x.replace(\"janeiro/\", \"\").replace(\"fevereiro/\", \"\").replace(\"março/\", \"\").\n",
    "                               replace(\"abril/\", \"\").replace(\"maio/\", \"\").replace(\"junho/\", \"\").replace(\"julho/\", \"\").replace(\"agosto/\", \"\").\n",
    "                               replace(\"setembro/\", \"\").replace(\"outubro/\", \"\").replace(\"novembro/\", \"\").replace(\"dezembro/\", \"\"))\n",
    "    \n",
    "    wanted_years = ['17', '18', '19', '20', '21', '22']\n",
    "    for years in wanted_years:\n",
    "        if years not in dataframes[df_name].columns:\n",
    "            dataframes[df_name].insert(3, years, ['-'], allow_duplicates = True)\n",
    "            \n",
    "    #dataframes[df_name] = dataframes[df_name][['CSV Nome','UF', '17', '18', '19', '20', '21', '22']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in dataframes.items():\n",
    "    dataframes[df_name]=dataframes[df_name][['UF','17', '18', '19', '20', '21', '22']]\n",
    "    dataframes[df_name]=pd.melt(dataframes[df_name], id_vars='UF',value_vars=['17','18','19','20','21','22'])\n",
    "    dataframes[df_name]['index']=dataframes[df_name].groupby(['UF', 'variable']).cumcount()\n",
    "    dataframes[df_name] = pd.pivot_table(dataframes[df_name], index=['UF', 'index'], columns='variable', values='value', aggfunc='first')\n",
    "    dataframes[df_name].reset_index(inplace=True)\n",
    "    dataframes[df_name].fillna('-',inplace=True)\n",
    "    dataframes[df_name]['CSV Nome'] = df_name\n",
    "    \n",
    "    year_map = {\n",
    "        '17':'2017',\n",
    "        '18':'2018',\n",
    "        '19':'2019',\n",
    "        '20':'2020',\n",
    "        '21':'2021',\n",
    "        '22':'2022'\n",
    "    }\n",
    "    \n",
    "    dataframes[df_name].rename(columns=year_map,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CSV Nome  ESTADOS  UF  Mes            2017            2018   \n",
      "0    CIDEEST  ALAGOAS  AL    1   4.492.196,43    4.485.114,67   \\\n",
      "1    CIDEEST  ALAGOAS  AL    2            -               -      \n",
      "2    CIDEEST  ALAGOAS  AL    3            -               -      \n",
      "3    CIDEEST  ALAGOAS  AL    4   4.186.247,93    3.937.748,87    \n",
      "4    CIDEEST  ALAGOAS  AL    5            -               -      \n",
      "..       ...      ...  ..  ...             ...             ...   \n",
      "175      TCP  ALAGOAS  AL    8     165.318,95        7.270,00    \n",
      "176      TCP  ALAGOAS  AL    9      90.097,05             -      \n",
      "177      TCP  ALAGOAS  AL   10      93.628,44             -      \n",
      "178      TCP  ALAGOAS  AL   11      88.028,54             -      \n",
      "179      TCP  ALAGOAS  AL   12     116.186,27             -      \n",
      "\n",
      "               2019            2020          2021            2022  \n",
      "0     2.295.681,62    2.141.474,89    966.410,06    2.230.921,30   \n",
      "1              -               -             -               -     \n",
      "2              -               -             -               -     \n",
      "3     2.197.306,74    1.940.927,47    803.948,64    2.547.525,07   \n",
      "4              -               -             -               -     \n",
      "..              ...             ...           ...             ...  \n",
      "175               -               -             -               -  \n",
      "176               -               -             -               -  \n",
      "177               -               -             -               -  \n",
      "178               -               -             -               -  \n",
      "179               -               -             -               -  \n",
      "\n",
      "[180 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#create output dataframe\n",
    "output_columns = ['CSV Nome', 'ESTADOS', 'UF', 'Mes', '2017', '2018', '2019', '2020', '2021', '2022']\n",
    "output_df = pd.DataFrame(columns = output_columns)\n",
    "dfs_conc = list(dataframes.values())\n",
    "output_df=pd.concat(dfs_conc,axis=0,ignore_index=True)\n",
    "\n",
    "output_df['Mes']=list(range(1,13))*count_dfs\n",
    "output_df['ESTADOS'] = 'ALAGOAS'\n",
    "output_df['UF'] = 'AL'\n",
    "output_df.drop('index',axis=1,inplace=True)\n",
    "output_df.columns.name=''\n",
    "\n",
    "output_df=output_df[['CSV Nome', 'ESTADOS', 'UF', 'Mes', '2017','2018','2019','2020','2021','2022']]\n",
    "\n",
    "print(output_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
